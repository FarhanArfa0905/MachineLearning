# -*- coding: utf-8 -*-
"""Untitled7.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1Y_NNGEdqIUIttKeQqxrUCwYQt178-r9i

# Set up
"""

#Common Imports
import os
import numpy as np
import tensorflow as tf
import pandas as pd
import pickle
from tensorflow import keras

#Data Visualization
import matplotlib.pyplot as plt

#Model Architecture
from tensorflow.keras import Sequential
from tensorflow.keras.layers import Dropout, Dense

# Model Training
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping

#LabelEncoder
from sklearn.preprocessing import LabelEncoder, MinMaxScaler

"""# Data Preparation"""

# Constants
BATCH_SIZE = 32 # number of samples per gradient update
EPOCHS = 30 # number of epoch to train models how much

# Hyperparameters
LEARNING_RATE = 1e-3 # learning rate for the optimizer

# Model training
LOSS = 'mse'
METRICS = ['mae']

"""Datasets Path"""

# Dataset Paths
file_path = "Transaction_Data.csv"

"""Check Configuration"""

# Print configuration to check our setting before
print(f"Batch Size: {BATCH_SIZE}")
print(f"Epochs: {EPOCHS}")
print(f"Learning Rate: {LEARNING_RATE}")
print(f"Loss: {LOSS}")
print(f"Metrics: {METRICS}")
print(f"Dataset Path: {file_path}")

"""Load Dataset"""

data = pd.read_csv(file_path)
data['date'] = pd.to_datetime(data['date'])

"""Check Dataset"""

# Display first few rows of the dataset to check our Dataset we have
print("\nSample Data:")
print(data.head())

# Dataset summary, check our dataset type for each column
print("\nDataset Summary:")
print(data.info())

"""# Data Preprocessing"""

#Make a preprocessing data like do labeling in category and scalarizer 0-1 in amount column
def preprocess_data(data, le_category=None, scaler=None):
    data['month'] = data['date'].dt.month
    data['day'] = data['date'].dt.day

    # Encode 'category'
    if le_category is None:
        le_category = LabelEncoder()
        data['category_encoded'] = le_category.fit_transform(data['category'])
    else:
        data['category_encoded'] = le_category.transform(data['category'])

    # Scale 'amount'
    if scaler is None:
        scaler = MinMaxScaler()
        data['amount_scaled'] = scaler.fit_transform(data[['amount']])
    else:
        data['amount_scaled'] = scaler.transform(data[['amount']])

    return data, le_category, scaler

"""Filter Expense Data Only For Training"""

# Filter only 'Expense' data in column type
filtered_data = data[data['type'] == 'Expense']
filtered_data, le_category, scaler = preprocess_data(filtered_data)

"""Setup X and Y as input and output"""

# Prepare features and labels
X = filtered_data[['category_encoded', 'month', 'day']].values
y = filtered_data['amount_scaled'].values

print("\nPreprocessed Data:")
print(filtered_data.head())

"""#Build Model

Model Architecture
"""

#Model Arhitecture with sequential model
def build_model(input_shape):
    model = tf.keras.Sequential([
        tf.keras.layers.Input(shape=(input_shape,)),

        # Dense Block 1
        tf.keras.layers.Dense(256, activation='relu', kernel_regularizer='l2'),
        tf.keras.layers.Dropout(0.3),

        # Dense Block 2
        tf.keras.layers.Dense(128, activation='relu', kernel_regularizer='l2'),
        tf.keras.layers.Dropout(0.2),

        # Dense Block 3
        tf.keras.layers.Dense(64, activation='relu', kernel_regularizer='l2'),
        tf.keras.layers.Dropout(0.1),

        # Output Layer
        tf.keras.layers.Dense(1, activation='linear')
    ])
    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=LEARNING_RATE),
                  loss=LOSS,
                  metrics=METRICS)
    return model

model = build_model(X.shape[1])
model.summary()

"""Plot Function to show The Progress"""

#Visualization Training Function to monitoring the progress
def plot_training(history):
    """
    Plot training loss and metrics over epochs.
    """
    history_dict = history.history
    plt.figure(figsize=(10, 6))
    plt.plot(history_dict['loss'], label='Training Loss')
    plt.plot(history_dict['val_loss'], label='Validation Loss')
    plt.title('Training and Validation Loss')
    plt.xlabel('Epochs')
    plt.ylabel('Loss')
    plt.legend()
    plt.grid()
    plt.show()

"""#Train The Model"""

#Setup Early stop if the progress is flat
early_stopping = EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True)

history = model.fit(X, y,
                    validation_split=0.2,
                    epochs=EPOCHS,
                    batch_size=BATCH_SIZE,
                    callbacks=[early_stopping],
                    verbose=1)

plot_training(history)

"""Evaluate"""

loss, mae = model.evaluate(X, y, verbose=0)
print(f"\nModel Evaluation:\n - Loss (MSE): {loss:.4f}\n - MAE: {mae:.4f}")

"""Saved The model to next Progress Deployment"""

# Save the trained model
model.save('budget_suggestion_model.h5')

# Save preprocessors
with open('label_encoder.pkl', 'wb') as f:
    pickle.dump(le_category, f)

with open('scaler.pkl', 'wb') as f:
    pickle.dump(scaler, f)

print("Model and preprocessors saved successfully.")

"""# Result Recommendation Budgeting"""

#Test Generate Function Recommendation in Model.py
# Total Expense * each category percent for total Expense they do
# For Example Total Expense User_1 in period 3 month = 3.500.000
# and for each category he have 3 category did he use in transaction in 3 month period
# Food = 39.56% transport = 31.56 others = 28.88 and will do recommendation each persent * total expense
# and in the next the budgeting will different depend history he doing in transactions.
def generate_recommendations(data, user_id_col='user_id', categories_col='category_encoded', amount_col='amount', le_category=None):
    """
    Generate dynamic budget recommendations based on user spending patterns over all available months.
    """
    # Group data by user and category to sum expenses
    user_expenses = data.groupby([user_id_col, categories_col])[amount_col].sum().reset_index()

    # Calculate total expenses per user
    total_expenses = user_expenses.groupby(user_id_col)[amount_col].sum()

    recommendations = {}
    for user, total in total_expenses.items():
        # User specific data
        user_data = user_expenses[user_expenses[user_id_col] == user]

        # Months of data available for the user
        num_months = data[data[user_id_col] == user]['month'].nunique()

        # Calculate average monthly expenses
        monthly_average = total / num_months if num_months else 0

        # Calculate category distribution and budget recommendation
        category_distribution = user_data.set_index(categories_col)[amount_col] / total
        budget_recommendation = {
            le_category.inverse_transform([int(category)])[0]: round(percent * monthly_average, 2)
            for category, percent in category_distribution.items()
        }
        recommendations[user] = budget_recommendation

    return recommendations

# Example of using this function
# Call by user_id
budget_recommendations = generate_recommendations(filtered_data,
                                                  user_id_col='user_id',
                                                  categories_col='category_encoded',
                                                  amount_col='amount',
                                                  le_category=le_category)

print("Budget Recommendations:")
print(budget_recommendations)

# Convert recommendations to a DataFrame for visualization
recommendations_list = []
for user, categories in budget_recommendations.items():
    for category, budget in categories.items():
        recommendations_list.append({'User': user, 'Category': category, 'Budget Recommendation': budget})

recommendations_df = pd.DataFrame(recommendations_list)
print("Budget Recommendations:")
print(recommendations_df)

# Filter recommendations for a specific user
user_to_display = '59'  # Ganti dengan user yang ingin ditampilkan
filtered_recommendations_df = recommendations_df[recommendations_df['User'] == user_to_display]

# Display filtered recommendations
print(f"Budget Recommendations for {user_to_display}:")
print(filtered_recommendations_df)

import plotly.graph_objects as go

# Buat tabel dengan Plotly
def plotly_table(dataframe):
    header_values = list(dataframe.columns)
    cell_values = [dataframe[col].tolist() for col in dataframe.columns]

    fig = go.Figure(data=[go.Table(
        header=dict(
            values=header_values,
            fill_color='paleturquoise',
            align='left'
        ),
        cells=dict(
            values=cell_values,
            fill_color='lavender',
            align='left')
    )])

    fig.show()

# Panggil fungsi dengan DataFrame kamu
plotly_table(recommendations_df)